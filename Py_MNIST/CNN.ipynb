{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#ignore warning messages \n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore') \n",
    "\n",
    "# sns.set()\n",
    "\n",
    "###### Voor Tensorflow-GPU ########\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train = pd.read_csv(\"Data/train.csv\")\n",
    "test = pd.read_csv(\"Data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = train[\"label\"]\n",
    "Y_test = test[\"label\"]\n",
    "\n",
    "# Drop 'label' column\n",
    "X_train = train.drop(labels = [\"label\"],axis = 1) \n",
    "X_test = test.drop(labels = [\"label\"],axis = 1) \n",
    "\n",
    "# free some space\n",
    "del train \n",
    "del test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape image in 3 dimensions (height = 28px, width = 28px , channel = 1)\n",
    "X_train = X_train.values.reshape(-1,28,28,1)\n",
    "X_test = X_test.values.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\n",
    "Y_train = to_categorical(Y_train, num_classes = 10)\n",
    "Y_test = to_categorical(Y_test, num_classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the train and the validation set for the fitting\n",
    "# X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = plt.imshow(X_train[2], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the CNN model \n",
    "# my CNN architechture is In -> [[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out\n",
    "\n",
    "model = Sequential(name=\"mnist_model\")\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (28,28,1), name=\"mnist_input\"))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation = \"softmax\", name=\"mnist_output\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer\n",
    "# optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mnist_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mnist_input (Conv2D)         (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "mnist_output (Dense)         (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 887,530\n",
      "Trainable params: 887,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer = \"adam\" , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a learning rate annealer\n",
    "# learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "#                                             patience=3, \n",
    "#                                             verbose=1, \n",
    "#                                             factor=0.5, \n",
    "#                                             min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopper = EarlyStopping(patience=5, verbose=1)\n",
    "epochs = 100 # Turn epochs to 30 to get 0.9967 accuracy\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without data augmentation i obtained an accuracy of 0.98114\n",
    "#history = model.fit(X_train, Y_train, batch_size = batch_size, epochs = epochs, \n",
    "#          validation_data = (X_val, Y_val), verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With data augmentation to prevent overfitting (accuracy 0.99286)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-19-21221503c378>:2: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/3\n",
      "937/938 [============================>.] - ETA: 0s - loss: 0.3987 - accuracy: 0.8715WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_test_batch_end` time: 0.0020s). Check your callbacks.\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.3986 - accuracy: 0.8715 - val_loss: 0.0597 - val_accuracy: 0.9810\n",
      "Epoch 2/3\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.1453 - accuracy: 0.9572 - val_loss: 0.0371 - val_accuracy: 0.9877\n",
      "Epoch 3/3\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.1059 - accuracy: 0.9690 - val_loss: 0.0431 - val_accuracy: 0.9854\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n",
    "                              epochs = 3, validation_data = (X_test,Y_test),\n",
    "                              verbose = 1, callbacks=[earlystopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAANxklEQVR4nO3dXahd9ZnH8d8vbxptwWRkYkidsVO8MIyMKUEHjINDnWpEiL0pzYU4mcLpRS0NCNOQuagwDMjMNDIXYyGdhiRDx1jwpVoGWxvKOBOkGsXRvGh9S4gh5uhEqEUxb89cnJVyGs/+r5O91t5rJc/3A4ezz3rO2vtxH3/Za6///q+/I0IALnxzum4AwHgQdiAJwg4kQdiBJAg7kMS8cT6YbU79AyMWEZ5pe6Ow275N0r9Imivp3yLi/ib3l9WcOeUDrNOnTxfr8+YN/jOePHlyqJ7OmDt3brF+6tSpRveP8Rn6MN72XEn/Kmm1pOWS1tpe3lZjANrV5D379ZLeiIi3IuK4pB2S1rTTFoC2NQn7MkmHpv38TrXt99iesL3b9u4GjwWgoZGfoIuIzZI2S5ygA7rU5JX9sKQrp/38uWobgB5qEvbnJV1t+/O2F0j6mqQn2mkLQNuGPoyPiJO275H0M00NvW2JiL2tdXYBKQ2NSc2Hx5rsP3/+/GL9xIkTQ983+sXjnOKa9T37qMPeBGG/8Az6UA0flwWSIOxAEoQdSIKwA0kQdiAJwg4kwdBbD4xyGmnT6bN1FixYUKwfP3680f3j3DH0BiRH2IEkCDuQBGEHkiDsQBKEHUiCobfzQJOhubqht6Z/fxYG7R+G3oDkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcbZx6DPV5dtatRTaHHuGGcHkiPsQBKEHUiCsANJEHYgCcIOJEHYgSQYZz8P2DMOm85K3d+3bq583f6Mo/fPoHH2oddnlyTbByR9KOmUpJMRsbLJ/QEYnUZhr/xlRLzfwv0AGCHeswNJNA17SPq57RdsT8z0C7YnbO+2vbvhYwFooNEJOtvLIuKw7T+U9LSkb0XEM4Xf5wTdEDhBh3MxkokwEXG4+j4p6TFJ1ze5PwCjM3TYbV9q+7Nnbkv6sqQ9bTUGoF1NzsYvkfRYdYg5T9J/RMRTrXR1gak7DK+bE37jjTcW6zfccMPA2qFDh4r77tixo1jHhWPosEfEW5L+rMVeAIwQQ29AEoQdSIKwA0kQdiAJwg4kwRTXMagbetu0aVOxvn79+mJ9+/btA2t33XVXcd9nn322WF+1alWxzpLN/cOlpIHkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcbZx6BuCmvdks3Lly8v1l977bWBtbq/b139mmuuKdZfffXVYh3jxzg7kBxhB5Ig7EAShB1IgrADSRB2IAnCDiTRxsKOqFG3asq9995brO/du7dYv/baawfW9u3bV9z34YcfLtZXr15drJfG+CXmu/cJr+xAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATj7GMwd+7cYv2BBx4o1j/44INivTQOv2LFiuK+dePgp06darQ/+qP2ld32FtuTtvdM27bY9tO2X6++LxptmwCams1h/FZJt521bYOknRFxtaSd1c8Aeqw27BHxjKRjZ21eI2lbdXubpDvbbQtA24Z9z74kIo5Ut9+VtGTQL9qekDQx5OMAaEnjE3QREaULSUbEZkmbpbwXnAT6YNiht6O2l0pS9X2yvZYAjMKwYX9C0t3V7bsl/aSddgCMSu11420/JOlmSZdLOirpu5Iel/RjSX8k6aCkr0bE2SfxZrovDuNnUDcOXzfWfckllwysffzxx8V9P/roo2L9lltuKdZ37dpVrGP8Bl03vvY9e0SsHVD6UqOOAIwVH5cFkiDsQBKEHUiCsANJEHYgCZZsPg/YM46k/M68eYMHVUrDcpI0OVn+PNTChQuL9bre6oYN0T6WbAaSI+xAEoQdSIKwA0kQdiAJwg4kQdiBJLiU9BjUjUXPmVP+N7duyecTJ04MrG3ZsqW479atWxs9Ns4fvLIDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBLMZ++BunH4ur9RaT77J598Utx3wYIFxXrdfPSmvaN9zGcHkiPsQBKEHUiCsANJEHYgCcIOJEHYgSSYz94Ds1g2u1h/7733Bta2b99e3LduHL3pctLoj9pXdttbbE/a3jNt2322D9t+qfq6fbRtAmhqNofxWyXdNsP2ByLiuurrP9ttC0DbasMeEc9IOjaGXgCMUJMTdPfYfrk6zF806JdsT9jebXt3g8cC0NCwYf++pC9Iuk7SEUnfG/SLEbE5IlZGxMohHwtAC4YKe0QcjYhTEXFa0g8kXd9uWwDaNlTYbS+d9uNXJO0Z9LsA+qF2nN32Q5JulnS57XckfVfSzbavkxSSDkj6RhvNzJ8/v1gvXR+96bzqJtdub3rd97r9N27cWKyX5qyvW7euuC/rq+dRG/aIWDvD5h+OoBcAI8THZYEkCDuQBGEHkiDsQBKEHUhi7JeSLg0zNRmiqtu3y6madUOKy5YtK9bffvvtYv2iiy4aWDt+/Hhx36ZDlkyB7R8uJQ0kR9iBJAg7kARhB5Ig7EAShB1IgrADSYz9UtKl8fC6Md8m+9aN9zaZplr32KWpuZL05ptvFus33XRTsd5kLLtuHL1uSee6cXz0B6/sQBKEHUiCsANJEHYgCcIOJEHYgSQIO5BEr5ZsrhuvLtXr5rPXaTIfvm6ce9euXcX6gw8+WKw/99xzxXrp8evmm2/YsKFY37RpU7HOfPbzB6/sQBKEHUiCsANJEHYgCcIOJEHYgSQIO5BEr64bX9dLk17rxvDrru1+xRVXDKwdPHiwuG/dWHPdWPWTTz5ZrJeWbL7jjjuK+1588cXF+rx55Y9iMI7eP0NfN972lbZ/aXuf7b22v11tX2z7aduvV98Xtd00gPbM5jD+pKR7I2K5pD+X9E3byyVtkLQzIq6WtLP6GUBP1YY9Io5ExIvV7Q8l7Ze0TNIaSduqX9sm6c4R9QigBef02XjbV0laIelXkpZExJGq9K6kJQP2mZA00aBHAC2Y9dl425+R9Iik9RHxm+m1mDpzNuPZs4jYHBErI2Jlo04BNDKrsNuer6mg/ygiHq02H7W9tKovlTQ5mhYBtKF26M1TY1bbJB2LiPXTtv+TpP+LiPttb5C0OCL+tua+ig/WdPngkrqhtbrLPT/++OMDa7feemtx34ULFxbrl112WbG+bt26Yr1k//79xfpTTz1VrDOF9fwzaOhtNu/Zb5R0l6RXbL9Ubdso6X5JP7b9dUkHJX21hT4BjEht2CPifyQNesn9UrvtABgVPi4LJEHYgSQIO5AEYQeSIOxAEmOf4tpw/4G1pv8ddePJpUtNN33sJstF1xn1ksuMw/fP0FNcAVwYCDuQBGEHkiDsQBKEHUiCsANJEHYgifNqnL3mvov1cf53jltpnL5ujH6UY/zoBuPsQHKEHUiCsANJEHYgCcIOJEHYgSQIO5DEBTPODmAK4+xAcoQdSIKwA0kQdiAJwg4kQdiBJAg7kERt2G1fafuXtvfZ3mv729X2+2wftv1S9XX76NsFMKzaD9XYXippaUS8aPuzkl6QdKem1mP/bUT886wfjA/VACM36EM1s1mf/YikI9XtD23vl7Ss3fYAjNo5vWe3fZWkFZJ+VW26x/bLtrfYXjRgnwnbu23vbtYqgCZm/dl425+R9F+S/iEiHrW9RNL7kkLS32vqUP9vau6Dw3hgxAYdxs8q7LbnS/qppJ9FxKYZ6ldJ+mlE/GnN/RB2YMSGngjjqcu2/lDS/ulBr07cnfEVSXuaNglgdGZzNn6VpP+W9IqkM9cV3ihpraTrNHUYf0DSN6qTeaX74pUdGLFGh/FtIezA6DGfHUiOsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kETtBSdb9r6kg9N+vrza1kd97a2vfUn0Nqw2e/vjQYWxzmf/1IPbuyNiZWcNFPS1t772JdHbsMbVG4fxQBKEHUii67Bv7vjxS/raW1/7kuhtWGPprdP37ADGp+tXdgBjQtiBJDoJu+3bbL9m+w3bG7roYRDbB2y/Ui1D3en6dNUaepO290zbttj207Zfr77PuMZeR731YhnvwjLjnT53XS9/Pvb37LbnSvq1pL+S9I6k5yWtjYh9Y21kANsHJK2MiM4/gGH7LyT9VtL2M0tr2f5HScci4v7qH8pFEfGdnvR2n85xGe8R9TZomfG/VofPXZvLnw+ji1f26yW9ERFvRcRxSTskremgj96LiGckHTtr8xpJ26rb2zT1P8vYDeitFyLiSES8WN3+UNKZZcY7fe4KfY1FF2FfJunQtJ/fUb/Wew9JP7f9gu2JrpuZwZJpy2y9K2lJl83MoHYZ73E6a5nx3jx3wyx/3hQn6D5tVUR8UdJqSd+sDld7Kabeg/Vp7PT7kr6gqTUAj0j6XpfNVMuMPyJpfUT8Znqty+duhr7G8rx1EfbDkq6c9vPnqm29EBGHq++Tkh7T1NuOPjl6ZgXd6vtkx/38TkQcjYhTEXFa0g/U4XNXLTP+iKQfRcSj1ebOn7uZ+hrX89ZF2J+XdLXtz9teIOlrkp7ooI9PsX1pdeJEti+V9GX1bynqJyTdXd2+W9JPOuzl9/RlGe9By4yr4+eu8+XPI2LsX5Ju19QZ+Tcl/V0XPQzo608k/W/1tbfr3iQ9pKnDuhOaOrfxdUl/IGmnpNcl/ULS4h719u+aWtr7ZU0Fa2lHva3S1CH6y5Jeqr5u7/q5K/Q1lueNj8sCSXCCDkiCsANJEHYgCcIOJEHYgSQIO5AEYQeS+H8KSgZe+m52xwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dink = [0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 4, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 2, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 62, 117, 88, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 143, 255, 161, 254, 197, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 254, 41, 1, 0, 255, 40, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 113, 253, 42, 0, 168, 114, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 96, 255, 49, 167, 110, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 10, 1, 247, 59, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 5, 15, 249, 2, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 1, 0, 173, 153, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 4, 253, 3, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 239, 159, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 1, 0, 2, 0, 2, 0, 2, 124, 232, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 3, 0, 0, 0, 5, 32, 255, 6, 0, 1, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 2, 0, 1, 0, 253, 60, 3, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 3, 0, 197, 148, 6, 0, 3, 123, 9, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 1, 6, 30, 255, 252, 255, 178, 171, 247, 255, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 5, 0, 176, 247, 0, 16, 114, 113, 72, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 3, 1, 0, 0, 2, 0, 0, 6, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "dink = np.array(dink)\n",
    "dink = dink / 255.0\n",
    "g = plt.imshow(dink.reshape(28,28,1), cmap=\"gray\")\n",
    "dink = dink.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(dink.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.2070024e-03 1.9703157e-02 9.2631882e-01 7.7522853e-03 1.8475542e-02\n",
      " 5.5389269e-04 3.4505682e-04 5.0113611e-03 8.4554972e-03 1.1177304e-02]\n",
      "0 has prob of 0.0\n",
      "1 has prob of 0.019999999552965164\n",
      "2 has prob of 0.9300000071525574\n",
      "3 has prob of 0.009999999776482582\n",
      "4 has prob of 0.019999999552965164\n",
      "5 has prob of 0.0\n",
      "6 has prob of 0.0\n",
      "7 has prob of 0.009999999776482582\n",
      "8 has prob of 0.009999999776482582\n",
      "9 has prob of 0.009999999776482582\n",
      "Closest number is 2\n"
     ]
    }
   ],
   "source": [
    "# predict results\n",
    "results = model.predict(dink)\n",
    "print(results[0])\n",
    "for i in results[0]:\n",
    "    print(f\"{np.where(results[0] == i)[0][0]} has prob of {round(i,2)}\")\n",
    "\n",
    "# select the indix with the maximum probability\n",
    "results = np.argmax(results,axis = 1)\n",
    "print(f\"Closest number is {results[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.2070024e-03 1.9703157e-02 9.2631882e-01 7.7522853e-03 1.8475542e-02\n",
      "  5.5389269e-04 3.4505682e-04 5.0113611e-03 8.4554972e-03 1.1177304e-02]]\n"
     ]
    }
   ],
   "source": [
    "results = model.predict(dink)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras2onnx version is 1.8.0\n"
     ]
    }
   ],
   "source": [
    "# KERAS MODEL OPSLAAN\n",
    "\n",
    "import keras2onnx\n",
    "print(\"keras2onnx version is \"+keras2onnx.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "Processing a keras layer - (mnist_output: <class 'tensorflow.python.keras.layers.core.Dense'>)\n",
      "\toutput: mnist_output/Softmax:0\n",
      "\tinput : dropout_2/cond/Identity:0\n",
      "Processing a keras layer - (dropout_2: <class 'tensorflow.python.keras.layers.core.Dropout'>)\n",
      "\toutput: dropout_2/cond/Identity:0\n",
      "\tinput : dense/Relu:0\n",
      "Processing a keras layer - (dense: <class 'tensorflow.python.keras.layers.core.Dense'>)\n",
      "\toutput: dense/Relu:0\n",
      "\tinput : flatten/Reshape:0\n",
      "Processing a keras layer - (flatten: <class 'tensorflow.python.keras.layers.core.Flatten'>)\n",
      "\toutput: flatten/Reshape:0\n",
      "\tinput : dropout_1/cond/Identity:0\n",
      "Processing a keras layer - (dropout_1: <class 'tensorflow.python.keras.layers.core.Dropout'>)\n",
      "\toutput: dropout_1/cond/Identity:0\n",
      "\tinput : max_pooling2d_1/MaxPool:0\n",
      "Processing a keras layer - (max_pooling2d_1: <class 'tensorflow.python.keras.layers.pooling.MaxPooling2D'>)\n",
      "\toutput: max_pooling2d_1/MaxPool:0\n",
      "\tinput : conv2d_2/Relu:0\n",
      "Processing a keras layer - (conv2d_2: <class 'tensorflow.python.keras.layers.convolutional.Conv2D'>)\n",
      "\toutput: conv2d_2/Relu:0\n",
      "\tinput : conv2d_1/Relu:0\n",
      "Processing a keras layer - (conv2d_1: <class 'tensorflow.python.keras.layers.convolutional.Conv2D'>)\n",
      "\toutput: conv2d_1/Relu:0\n",
      "\tinput : dropout/cond/Identity:0\n",
      "Processing a keras layer - (dropout: <class 'tensorflow.python.keras.layers.core.Dropout'>)\n",
      "\toutput: dropout/cond/Identity:0\n",
      "\tinput : max_pooling2d/MaxPool:0\n",
      "Processing a keras layer - (max_pooling2d: <class 'tensorflow.python.keras.layers.pooling.MaxPooling2D'>)\n",
      "\toutput: max_pooling2d/MaxPool:0\n",
      "\tinput : conv2d/Relu:0\n",
      "Processing a keras layer - (conv2d: <class 'tensorflow.python.keras.layers.convolutional.Conv2D'>)\n",
      "\toutput: conv2d/Relu:0\n",
      "\tinput : mnist_input/Relu:0\n",
      "Processing a keras layer - (mnist_input: <class 'tensorflow.python.keras.layers.convolutional.Conv2D'>)\n",
      "\toutput: mnist_input/Relu:0\n",
      "\tinput : mnist_input_input:0\n",
      "var: mnist_input_input\n",
      "var: mnist_input_input:0\n",
      "var: mnist_input_input:01\n",
      "var: mnist_input/Relu:0\n",
      "var: conv2d/Relu:0\n",
      "var: max_pooling2d/MaxPool:0\n",
      "var: dropout/cond/Identity:0\n",
      "var: conv2d_1/Relu:0\n",
      "var: conv2d_2/Relu:0\n",
      "var: max_pooling2d_1/MaxPool:0\n",
      "var: dropout_1/cond/Identity:0\n",
      "var: flatten/Reshape:0\n",
      "var: dense/Relu:0\n",
      "var: dropout_2/cond/Identity:0\n",
      "var: mnist_output/Softmax:01\n",
      "var: mnist_output/Softmax:0\n",
      "var: mnist_output\n",
      "Converting the operator (Identity): Identity\n",
      "Converting the operator (Identity1): Identity\n",
      "Converting the operator (Identity2): Identity\n",
      "Converting the operator (mnist_output): <class 'tensorflow.python.keras.layers.core.Dense'>\n",
      "Converting the operator (dropout_2): <class 'tensorflow.python.keras.layers.core.Dropout'>\n",
      "Converting the operator (keras_learning_phase/input): Const\n",
      "Converting the operator (dense): <class 'tensorflow.python.keras.layers.core.Dense'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mnist_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mnist_input (Conv2D)         (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "mnist_output (Dense)         (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 887,530\n",
      "Trainable params: 887,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting the operator (flatten): <class 'tensorflow.python.keras.layers.core.Flatten'>\n",
      "Converting the operator (flatten/Const): Const\n",
      "Converting the operator (dropout_1): <class 'tensorflow.python.keras.layers.core.Dropout'>\n",
      "Converting the operator (max_pooling2d_1): <class 'tensorflow.python.keras.layers.pooling.MaxPooling2D'>\n",
      "Converting the operator (conv2d_2): <class 'tensorflow.python.keras.layers.convolutional.Conv2D'>\n",
      "Converting the operator (conv2d_1): <class 'tensorflow.python.keras.layers.convolutional.Conv2D'>\n",
      "Converting the operator (dropout): <class 'tensorflow.python.keras.layers.core.Dropout'>\n",
      "Converting the operator (max_pooling2d): <class 'tensorflow.python.keras.layers.pooling.MaxPooling2D'>\n",
      "Converting the operator (conv2d): <class 'tensorflow.python.keras.layers.convolutional.Conv2D'>\n",
      "Converting the operator (mnist_input): <class 'tensorflow.python.keras.layers.convolutional.Conv2D'>\n",
      "Converting the operator (Identity3): Identity\n"
     ]
    }
   ],
   "source": [
    "# convert to onnx model OLD\n",
    "onnx_model = keras2onnx.convert_keras(model, 'mnist-onnx-js-v1', target_opset=7, debug_mode=1)\n",
    "output_model_path = \"./mnist-onnx-js-v1.onnx\"\n",
    "# and save the model in ONNX format\n",
    "keras2onnx.save_model(onnx_model, output_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "Processing a keras layer - (mnist_output: <class 'tensorflow.python.keras.layers.core.Dense'>)\n",
      "\toutput: mnist_output/Softmax:0\n",
      "\tinput : dropout_2/cond/Identity:0\n",
      "Processing a keras layer - (dropout_2: <class 'tensorflow.python.keras.layers.core.Dropout'>)\n",
      "\toutput: dropout_2/cond/Identity:0\n",
      "\tinput : dense/Relu:0\n",
      "Processing a keras layer - (dense: <class 'tensorflow.python.keras.layers.core.Dense'>)\n",
      "\toutput: dense/Relu:0\n",
      "\tinput : flatten/Reshape:0\n",
      "Processing a keras layer - (flatten: <class 'tensorflow.python.keras.layers.core.Flatten'>)\n",
      "\toutput: flatten/Reshape:0\n",
      "\tinput : dropout_1/cond/Identity:0\n",
      "Processing a keras layer - (dropout_1: <class 'tensorflow.python.keras.layers.core.Dropout'>)\n",
      "\toutput: dropout_1/cond/Identity:0\n",
      "\tinput : max_pooling2d_1/MaxPool:0\n",
      "Processing a keras layer - (max_pooling2d_1: <class 'tensorflow.python.keras.layers.pooling.MaxPooling2D'>)\n",
      "\toutput: max_pooling2d_1/MaxPool:0\n",
      "\tinput : conv2d_2/Relu:0\n",
      "Processing a keras layer - (conv2d_2: <class 'tensorflow.python.keras.layers.convolutional.Conv2D'>)\n",
      "\toutput: conv2d_2/Relu:0\n",
      "\tinput : conv2d_1/Relu:0\n",
      "Processing a keras layer - (conv2d_1: <class 'tensorflow.python.keras.layers.convolutional.Conv2D'>)\n",
      "\toutput: conv2d_1/Relu:0\n",
      "\tinput : dropout/cond/Identity:0\n",
      "Processing a keras layer - (dropout: <class 'tensorflow.python.keras.layers.core.Dropout'>)\n",
      "\toutput: dropout/cond/Identity:0\n",
      "\tinput : max_pooling2d/MaxPool:0\n",
      "Processing a keras layer - (max_pooling2d: <class 'tensorflow.python.keras.layers.pooling.MaxPooling2D'>)\n",
      "\toutput: max_pooling2d/MaxPool:0\n",
      "\tinput : conv2d/Relu:0\n",
      "Processing a keras layer - (conv2d: <class 'tensorflow.python.keras.layers.convolutional.Conv2D'>)\n",
      "\toutput: conv2d/Relu:0\n",
      "\tinput : mnist_input/Relu:0\n",
      "Processing a keras layer - (mnist_input: <class 'tensorflow.python.keras.layers.convolutional.Conv2D'>)\n",
      "\toutput: mnist_input/Relu:0\n",
      "\tinput : mnist_input_input:0\n",
      "var: mnist_input_input\n",
      "var: mnist_input_input:0\n",
      "var: mnist_input_input:01\n",
      "var: mnist_input/Relu:0\n",
      "var: conv2d/Relu:0\n",
      "var: max_pooling2d/MaxPool:0\n",
      "var: dropout/cond/Identity:0\n",
      "var: conv2d_1/Relu:0\n",
      "var: conv2d_2/Relu:0\n",
      "var: max_pooling2d_1/MaxPool:0\n",
      "var: dropout_1/cond/Identity:0\n",
      "var: flatten/Reshape:0\n",
      "var: dense/Relu:0\n",
      "var: dropout_2/cond/Identity:0\n",
      "var: mnist_output/Softmax:01\n",
      "var: mnist_output/Softmax:0\n",
      "var: mnist_output\n",
      "Converting the operator (Identity): Identity\n",
      "Converting the operator (Identity1): Identity\n",
      "Converting the operator (Identity2): Identity\n",
      "Converting the operator (mnist_output): <class 'tensorflow.python.keras.layers.core.Dense'>\n",
      "Converting the operator (dropout_2): <class 'tensorflow.python.keras.layers.core.Dropout'>\n",
      "Converting the operator (keras_learning_phase/input): Const\n",
      "Converting the operator (dense): <class 'tensorflow.python.keras.layers.core.Dense'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mnist_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mnist_input (Conv2D)         (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "mnist_output (Dense)         (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 887,530\n",
      "Trainable params: 887,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting the operator (flatten): <class 'tensorflow.python.keras.layers.core.Flatten'>\n",
      "Converting the operator (flatten/Const): Const\n",
      "Converting the operator (dropout_1): <class 'tensorflow.python.keras.layers.core.Dropout'>\n",
      "Converting the operator (max_pooling2d_1): <class 'tensorflow.python.keras.layers.pooling.MaxPooling2D'>\n",
      "Converting the operator (conv2d_2): <class 'tensorflow.python.keras.layers.convolutional.Conv2D'>\n",
      "Converting the operator (conv2d_1): <class 'tensorflow.python.keras.layers.convolutional.Conv2D'>\n",
      "Converting the operator (dropout): <class 'tensorflow.python.keras.layers.core.Dropout'>\n",
      "Converting the operator (max_pooling2d): <class 'tensorflow.python.keras.layers.pooling.MaxPooling2D'>\n",
      "Converting the operator (conv2d): <class 'tensorflow.python.keras.layers.convolutional.Conv2D'>\n",
      "Converting the operator (mnist_input): <class 'tensorflow.python.keras.layers.convolutional.Conv2D'>\n",
      "Converting the operator (Identity3): Identity\n"
     ]
    }
   ],
   "source": [
    "# convert to onnx model\n",
    "onnx_model = keras2onnx.convert_keras(model, 'mnist-onnx-v2', debug_mode=1)\n",
    "output_model_path = \"./mnist-onnx-v2.onnx\"\n",
    "# and save the model in ONNX format\n",
    "keras2onnx.save_model(onnx_model, output_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = onnxruntime.InferenceSession(\"mnist-onnx-v2.onnx\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist_input_input\n",
      "mnist_output\n"
     ]
    }
   ],
   "source": [
    "input_name = session.get_inputs()[0].name\n",
    "output_name = session.get_outputs()[0].name\n",
    "print(input_name)\n",
    "print(output_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.00536442, 0.08463484, 0.79872304, 0.01003877, 0.01352201,\n",
      "        0.00623415, 0.00249375, 0.02294048, 0.03221906, 0.02382956]],\n",
      "      dtype=float32)]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "result = session.run([output_name], {input_name: dink.astype('float32')})\n",
    "print(result)\n",
    "prediction=int(np.argmax(np.array(result).squeeze(), axis=0))\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"mnist_input_input:0\", shape=(None, 28, 28, 1), dtype=float32)\n",
      "mnist_output/Softmax:0\n"
     ]
    }
   ],
   "source": [
    "print(model.inputs[0])\n",
    "print(model.output.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict the test set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1195\n",
      "           1       1.00      0.99      1.00      1352\n",
      "           2       0.99      1.00      0.99      1157\n",
      "           3       0.99      0.99      0.99      1258\n",
      "           4       0.99      1.00      0.99      1140\n",
      "           5       1.00      0.99      0.99      1076\n",
      "           6       0.99      1.00      1.00      1167\n",
      "           7       0.99      0.99      0.99      1268\n",
      "           8       0.99      0.99      0.99      1174\n",
      "           9       0.99      0.97      0.98      1213\n",
      "\n",
      "    accuracy                           0.99     12000\n",
      "   macro avg       0.99      0.99      0.99     12000\n",
      "weighted avg       0.99      0.99      0.99     12000\n",
      "\n",
      "[[1188    0    0    0    0    0    6    0    1    0]\n",
      " [   1 1343    1    1    0    0    1    5    0    0]\n",
      " [   0    0 1155    2    0    0    0    0    0    0]\n",
      " [   0    0    3 1251    0    1    0    1    1    1]\n",
      " [   0    2    0    0 1135    0    0    0    0    3]\n",
      " [   0    0    0    4    0 1067    3    0    2    0]\n",
      " [   1    0    0    0    0    0 1166    0    0    0]\n",
      " [   0    0    8    1    2    0    0 1255    1    1]\n",
      " [   0    0    2    0    1    1    0    0 1168    2]\n",
      " [   4    0    0    3   14    1    0    6    5 1180]]\n",
      "99.23333333333333\n"
     ]
    }
   ],
   "source": [
    "print('Predict the test set')\n",
    "predict = model.predict(X_test, batch_size=batch_size)\n",
    "predict = np.argmax(predict,axis=1)\n",
    "class_report = classification_report(Y_test.argmax(axis=1),predict,target_names=[str(i) for i in range(10)])\n",
    "print(class_report)\n",
    "#run.log(\"Classification report\", class_report)\n",
    "\n",
    "cf = confusion_matrix(Y_test.argmax(axis=1), predict)\n",
    "#run.log(\"Confusion Matrix\", cf)\n",
    "\n",
    "print(cf)\n",
    "acc = accuracy_score(Y_test.argmax(axis=1), predict) * 100\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(X_test, batch_size=batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

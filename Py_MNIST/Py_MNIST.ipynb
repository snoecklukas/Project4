{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "from skimage.io import imread, imshow\n",
    "\n",
    "# distributions\n",
    "from scipy.stats import randint \n",
    "from scipy.stats import uniform\n",
    "\n",
    "\n",
    "# Import Keras libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import Dense, Dropout,BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from keras.layers import Input\n",
    "\n",
    "###### Voor Tensorflow-GPU ########\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Datasets\n",
    "\n",
    "df_train = pd.read_csv('Data/train.csv')\n",
    "df_test = pd.read_csv('Data/test.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop([\"label\"], axis=1)\n",
    "y_train = df_train[\"label\"]\n",
    "X_test = df_test.drop([\"label\"], axis=1)\n",
    "y_test = df_test[\"label\"]\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = X_train.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_model = np.reshape(df_list[0], (1,1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Negative dimension size caused by subtracting 5 from 1 for '{{node conv2d_2/Conv2D/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true](conv2d_2/Conv2D/Reshape, conv2d_2/Conv2D/Conv2D/ReadVariableOp)' with input shapes: [?,1,28,28], [5,5,28,8].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\piett\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[0;32m   1811\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1812\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1813\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Negative dimension size caused by subtracting 5 from 1 for '{{node conv2d_2/Conv2D/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true](conv2d_2/Conv2D/Reshape, conv2d_2/Conv2D/Conv2D/ReadVariableOp)' with input shapes: [?,1,28,28], [5,5,28,8].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-5175b3fdf48e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#    model.add(Dropout(0.3))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\piett\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\piett\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    204\u001b[0m           \u001b[1;31m# and create the node connecting the current layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m           \u001b[1;31m# to the input layer we just created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m           \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m           \u001b[0mset_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\piett\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    923\u001b[0m     \u001b[1;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    924\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 925\u001b[1;33m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[0;32m    926\u001b[0m                                                 input_list)\n\u001b[0;32m    927\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\piett\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1115\u001b[0m           \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1117\u001b[1;33m               \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\piett\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    245\u001b[0m       \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_causal_padding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convolution_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\piett\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\piett\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mconvolution_v2\u001b[1;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   1008\u001b[0m     \u001b[0mdilations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m     name=None):\n\u001b[1;32m-> 1010\u001b[1;33m   return convolution_internal(\n\u001b[0m\u001b[0;32m   1011\u001b[0m       \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1012\u001b[0m       \u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\piett\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mconvolution_internal\u001b[1;34m(input, filters, strides, padding, data_format, dilations, name, call_from_convolution, num_spatial_dims)\u001b[0m\n\u001b[0;32m   1138\u001b[0m         \u001b[0mop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv1d\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1140\u001b[1;33m       return op(\n\u001b[0m\u001b[0;32m   1141\u001b[0m           \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m           \u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\piett\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36m_conv2d_expanded_batch\u001b[1;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   2590\u001b[0m         \u001b[0mdilations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2591\u001b[0m         name=name)\n\u001b[1;32m-> 2592\u001b[1;33m   return squeeze_batch_dims(\n\u001b[0m\u001b[0;32m   2593\u001b[0m       \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2594\u001b[0m       functools.partial(\n",
      "\u001b[1;32mc:\\users\\piett\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36msqueeze_batch_dims\u001b[1;34m(inp, op, inner_rank, name)\u001b[0m\n\u001b[0;32m    311\u001b[0m           inp, array_ops.concat(([-1], inner_shape), axis=-1))\n\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 313\u001b[1;33m     \u001b[0mout_reshaped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp_reshaped\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    314\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m     \u001b[0mout_inner_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout_reshaped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0minner_rank\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\piett\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[0;32m    973\u001b[0m         \"'conv2d' Op, not %r.\" % dilations)\n\u001b[0;32m    974\u001b[0m   \u001b[0mdilations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_execute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"dilations\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_i\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdilations\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 975\u001b[1;33m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0m\u001b[0;32m    976\u001b[0m         \u001b[1;34m\"Conv2D\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    977\u001b[0m                   \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\piett\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    740\u001b[0m       \u001b[1;31m# Add Op to graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    741\u001b[0m       \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 742\u001b[1;33m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[0m\u001b[0;32m    743\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    744\u001b[0m                                  attrs=attr_protos, op_def=op_def)\n",
      "\u001b[1;32mc:\\users\\piett\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[0minp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m       \u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    592\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m         compute_device)\n",
      "\u001b[1;32mc:\\users\\piett\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3475\u001b[0m     \u001b[1;31m# Session.run call cannot occur between creating and mutating the op.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3476\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3477\u001b[1;33m       ret = Operation(\n\u001b[0m\u001b[0;32m   3478\u001b[0m           \u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3479\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\piett\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1972\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mop_def\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1973\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1974\u001b[1;33m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[0m\u001b[0;32m   1975\u001b[0m                                 control_input_ops, op_def)\n\u001b[0;32m   1976\u001b[0m       \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\piett\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[0;32m   1813\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1814\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1815\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1816\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1817\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Negative dimension size caused by subtracting 5 from 1 for '{{node conv2d_2/Conv2D/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true](conv2d_2/Conv2D/Reshape, conv2d_2/Conv2D/Conv2D/ReadVariableOp)' with input shapes: [?,1,28,28], [5,5,28,8]."
     ]
    }
   ],
   "source": [
    "input_dim = input_model.shape\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(8, kernel_size=(5,5), strides=(2,2), activation='relu',input_shape=input_dim)) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#    model.add(Dropout(0.3))\n",
    "#    model.add(BatchNormalization())\n",
    "model.add(Conv2D(100, (5,5), activation='relu')) \n",
    "model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "#    model.add(Dropout(0.3))\n",
    "#    model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten()) \n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(50, activation='relu')) \n",
    "\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(8, kernel_size=(5,5), activation='relu',input_shape=input_dim)) \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#     model.add(Dropout(0.3))\n",
    "#     model.add(BatchNormalization())\n",
    "    model.add(Conv2D(16, (5,5), activation='relu')) \n",
    "    model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "#     model.add(Dropout(0.3))\n",
    "#     model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Flatten()) \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(50, activation='relu')) \n",
    "\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Error converting shape to a TensorShape: Dimension value must be integer or None or have an __index__ method, got value '<tf.Tensor 'input_1:0' shape=(None, 1, 1, 28, 28) dtype=float32>' with type '<class 'tensorflow.python.framework.ops.Tensor'>'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\piett\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mmake_shape\u001b[1;34m(v, arg_name)\u001b[0m\n\u001b[0;32m    210\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m     \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\piett\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\u001b[0m in \u001b[0;36mas_shape\u001b[1;34m(shape)\u001b[0m\n\u001b[0;32m   1234\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1235\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mTensorShape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\piett\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, dims)\u001b[0m\n\u001b[0;32m    755\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Most common case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 756\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mDimension\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdims\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    757\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mdims\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\piett\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    755\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Most common case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 756\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mDimension\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdims\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    757\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mdims\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\piett\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    200\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m         six.raise_from(\n\u001b[0m\u001b[0;32m    202\u001b[0m             TypeError(\"Dimension value must be integer or None or have \"\n",
      "\u001b[1;32mc:\\users\\piett\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Dimension value must be integer or None or have an __index__ method, got value '<tf.Tensor 'input_1:0' shape=(None, 1, 1, 28, 28) dtype=float32>' with type '<class 'tensorflow.python.framework.ops.Tensor'>'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-1aca2645d9c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkernel_initializer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdropout_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkernel_initializer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\piett\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\piett\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    199\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_shape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m           \u001b[1;31m# Instantiate an input layer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m           x = input_layer.Input(\n\u001b[0m\u001b[0;32m    202\u001b[0m               batch_shape=batch_shape, dtype=dtype, name=layer.name + '_input')\n\u001b[0;32m    203\u001b[0m           \u001b[1;31m# This will build the current layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\piett\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_layer.py\u001b[0m in \u001b[0;36mInput\u001b[1;34m(shape, batch_size, name, dtype, sparse, tensor, ragged, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m     input_layer_config.update(\n\u001b[0;32m    310\u001b[0m         {'batch_size': batch_size, 'input_shape': shape})\n\u001b[1;32m--> 311\u001b[1;33m   \u001b[0minput_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInputLayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0minput_layer_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m   \u001b[1;31m# Return tensor including `_keras_history`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\piett\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_shape, batch_size, dtype, input_tensor, sparse, name, ragged, **kwargs)\u001b[0m\n\u001b[0;32m    153\u001b[0m       \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m         input_tensor = backend.placeholder(\n\u001b[0m\u001b[0;32m    156\u001b[0m             \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_input_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\piett\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mplaceholder\u001b[1;34m(shape, ndim, dtype, sparse, name, ragged)\u001b[0m\n\u001b[0;32m   1221\u001b[0m                                expand_composites=True)\n\u001b[0;32m   1222\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1223\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1225\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\piett\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mplaceholder\u001b[1;34m(dtype, shape, name)\u001b[0m\n\u001b[0;32m   3098\u001b[0m                        \"eager execution.\")\n\u001b[0;32m   3099\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3100\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\piett\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mplaceholder\u001b[1;34m(dtype, shape, name)\u001b[0m\n\u001b[0;32m   6805\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6806\u001b[0m     \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6807\u001b[1;33m   \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"shape\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6808\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0;32m   6809\u001b[0m         \"Placeholder\", dtype=dtype, shape=shape, name=name)\n",
      "\u001b[1;32mc:\\users\\piett\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mmake_shape\u001b[1;34m(v, arg_name)\u001b[0m\n\u001b[0;32m    211\u001b[0m     \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Error converting %s to a TensorShape: %s.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0marg_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m     raise ValueError(\"Error converting %s to a TensorShape: %s.\" % (arg_name,\n",
      "\u001b[1;31mTypeError\u001b[0m: Error converting shape to a TensorShape: Dimension value must be integer or None or have an __index__ method, got value '<tf.Tensor 'input_1:0' shape=(None, 1, 1, 28, 28) dtype=float32>' with type '<class 'tensorflow.python.framework.ops.Tensor'>'."
     ]
    }
   ],
   "source": [
    "activation = 'relu'\n",
    "dropout_rate = 0.2\n",
    "kernel_initializer ='uniform'\n",
    "optimizer = 'adam'\n",
    "lr = 0.01\n",
    "batchsize = 32\n",
    "\n",
    "input_img = Input(shape=(1,1,28,28))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=input_img, kernel_initializer=kernel_initializer,activation=activation))\n",
    "model.add(Dropout(dropout_rate))\n",
    "model.add(Dense(50, kernel_initializer=kernel_initializer,activation=activation))\n",
    "model.add(Dropout(dropout_rate))\n",
    "model.add(Dense(50, kernel_initializer=kernel_initializer,activation=activation))\n",
    "model.add(Dropout(dropout_rate))\n",
    "model.add(Dense(10, activation = 'softmax')) # 0-9 outputs\n",
    "\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy']) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "618/629 [============================>.] - ETA: 0s - loss: 0.6652 - accuracy: 0.7978\n",
      "Epoch 00001: val_loss improved from inf to 0.28008, saving model to MNIST.h5\n",
      "629/629 [==============================] - 3s 5ms/step - loss: 0.6606 - accuracy: 0.7993 - val_loss: 0.2801 - val_accuracy: 0.9192\n",
      "Epoch 2/50\n",
      "616/629 [============================>.] - ETA: 0s - loss: 0.3528 - accuracy: 0.9019\n",
      "Epoch 00002: val_loss improved from 0.28008 to 0.23110, saving model to MNIST.h5\n",
      "629/629 [==============================] - 3s 4ms/step - loss: 0.3526 - accuracy: 0.9019 - val_loss: 0.2311 - val_accuracy: 0.9383\n",
      "Epoch 3/50\n",
      "615/629 [============================>.] - ETA: 0s - loss: 0.2907 - accuracy: 0.9210\n",
      "Epoch 00003: val_loss improved from 0.23110 to 0.21743, saving model to MNIST.h5\n",
      "629/629 [==============================] - 3s 4ms/step - loss: 0.2904 - accuracy: 0.9211 - val_loss: 0.2174 - val_accuracy: 0.9435\n",
      "Epoch 4/50\n",
      "617/629 [============================>.] - ETA: 0s - loss: 0.2674 - accuracy: 0.9259\n",
      "Epoch 00004: val_loss did not improve from 0.21743\n",
      "629/629 [==============================] - 3s 4ms/step - loss: 0.2666 - accuracy: 0.9259 - val_loss: 0.2276 - val_accuracy: 0.9401\n",
      "Epoch 5/50\n",
      "626/629 [============================>.] - ETA: 0s - loss: 0.2329 - accuracy: 0.9372\n",
      "Epoch 00005: val_loss improved from 0.21743 to 0.20446, saving model to MNIST.h5\n",
      "629/629 [==============================] - 2s 4ms/step - loss: 0.2339 - accuracy: 0.9370 - val_loss: 0.2045 - val_accuracy: 0.9469\n",
      "Epoch 6/50\n",
      "621/629 [============================>.] - ETA: 0s - loss: 0.2250 - accuracy: 0.9394\n",
      "Epoch 00006: val_loss improved from 0.20446 to 0.19927, saving model to MNIST.h5\n",
      "629/629 [==============================] - 2s 4ms/step - loss: 0.2242 - accuracy: 0.9395 - val_loss: 0.1993 - val_accuracy: 0.9498\n",
      "Epoch 7/50\n",
      "617/629 [============================>.] - ETA: 0s - loss: 0.2029 - accuracy: 0.9462\n",
      "Epoch 00007: val_loss did not improve from 0.19927\n",
      "629/629 [==============================] - 3s 4ms/step - loss: 0.2025 - accuracy: 0.9463 - val_loss: 0.2010 - val_accuracy: 0.9497\n",
      "Epoch 8/50\n",
      "622/629 [============================>.] - ETA: 0s - loss: 0.1849 - accuracy: 0.9491\n",
      "Epoch 00008: val_loss did not improve from 0.19927\n",
      "629/629 [==============================] - 3s 4ms/step - loss: 0.1844 - accuracy: 0.9492 - val_loss: 0.2062 - val_accuracy: 0.9505\n",
      "Epoch 9/50\n",
      "616/629 [============================>.] - ETA: 0s - loss: 0.1804 - accuracy: 0.9490\n",
      "Epoch 00009: val_loss improved from 0.19927 to 0.19205, saving model to MNIST.h5\n",
      "629/629 [==============================] - 2s 4ms/step - loss: 0.1803 - accuracy: 0.9489 - val_loss: 0.1920 - val_accuracy: 0.9532\n",
      "Epoch 10/50\n",
      "619/629 [============================>.] - ETA: 0s - loss: 0.1666 - accuracy: 0.9536\n",
      "Epoch 00010: val_loss improved from 0.19205 to 0.18447, saving model to MNIST.h5\n",
      "629/629 [==============================] - 2s 4ms/step - loss: 0.1663 - accuracy: 0.9536 - val_loss: 0.1845 - val_accuracy: 0.9527\n",
      "Epoch 11/50\n",
      "626/629 [============================>.] - ETA: 0s - loss: 0.1692 - accuracy: 0.9541\n",
      "Epoch 00011: val_loss did not improve from 0.18447\n",
      "629/629 [==============================] - 2s 4ms/step - loss: 0.1692 - accuracy: 0.9541 - val_loss: 0.1897 - val_accuracy: 0.9512\n",
      "Epoch 12/50\n",
      "618/629 [============================>.] - ETA: 0s - loss: 0.1663 - accuracy: 0.9543\n",
      "Epoch 00012: val_loss did not improve from 0.18447\n",
      "629/629 [==============================] - 2s 4ms/step - loss: 0.1669 - accuracy: 0.9540 - val_loss: 0.1930 - val_accuracy: 0.9566\n",
      "Epoch 13/50\n",
      "619/629 [============================>.] - ETA: 0s - loss: 0.1583 - accuracy: 0.9572\n",
      "Epoch 00013: val_loss did not improve from 0.18447\n",
      "629/629 [==============================] - 2s 4ms/step - loss: 0.1589 - accuracy: 0.9574 - val_loss: 0.1863 - val_accuracy: 0.9564\n",
      "Epoch 14/50\n",
      "622/629 [============================>.] - ETA: 0s - loss: 0.1502 - accuracy: 0.9600\n",
      "Epoch 00014: val_loss did not improve from 0.18447\n",
      "629/629 [==============================] - 2s 4ms/step - loss: 0.1506 - accuracy: 0.9596 - val_loss: 0.2230 - val_accuracy: 0.9523\n",
      "Epoch 15/50\n",
      "616/629 [============================>.] - ETA: 0s - loss: 0.1443 - accuracy: 0.9597\n",
      "Epoch 00015: val_loss did not improve from 0.18447\n",
      "629/629 [==============================] - 2s 4ms/step - loss: 0.1448 - accuracy: 0.9595 - val_loss: 0.2012 - val_accuracy: 0.9556\n",
      "Epoch 00015: early stopping\n"
     ]
    }
   ],
   "source": [
    "earlystopper = EarlyStopping(patience=5, verbose=1)\n",
    "checkpointer = ModelCheckpoint('MNIST.h5', verbose=1, save_best_only=True)\n",
    "history = model.fit(X_train, \n",
    "                    y_train, \n",
    "                    epochs=50, \n",
    "                    callbacks=[earlystopper, checkpointer],\n",
    "                    validation_split=0.33, \n",
    "                    batch_size=batchsize,\n",
    "                    verbose=1).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['loss'])\n",
    "plt.plot(history['accuracy'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense\n",
      "dense_3\n"
     ]
    }
   ],
   "source": [
    "print(model.get_layer(index=0).name)\n",
    "print(model.get_layer(index=-1).name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'Session'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-a241a24fc789>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf2onnx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"input\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mx_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'Session'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tf2onnx\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    x = tf.placeholder(tf.float32, [2, 3], name=\"input\")\n",
    "    x_ = tf.add(x, x)\n",
    "    _ = tf.identity(x_, name=\"output\")\n",
    "    onnx_graph = tf2onnx.tfonnx.process_tf_graph(sess.graph, input_names=[\"input:0\"], output_names=[\"output:0\"])\n",
    "    model_proto = onnx_graph.make_model(\"test\")\n",
    "    with open(\"/tmp/model.onnx\", \"wb\") as f:\n",
    "        f.write(model_proto.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.2.3, however version 20.3.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n",
      "  ERROR: Error [WinError 2] The system cannot find the file specified while executing command git clone -q https://github.com/microsoft/onnxconverter-common 'C:\\Users\\piett\\AppData\\Local\\Temp\\pip-req-build-ojem0fbt'\n",
      "ERROR: Cannot find command 'git' - do you have 'git' installed and in your PATH?\n",
      "WARNING: You are using pip version 19.2.3, however version 20.3.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n",
      "  ERROR: Error [WinError 2] The system cannot find the file specified while executing command git clone -q https://github.com/onnx/keras-onnx 'C:\\Users\\piett\\AppData\\Local\\Temp\\pip-req-build-s7owwef0'\n",
      "ERROR: Cannot find command 'git' - do you have 'git' installed and in your PATH?\n",
      "WARNING: You are using pip version 19.2.3, however version 20.3.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# let's install the onnx packages from the source\n",
    "!pip install --quiet -U onnxruntime\n",
    "!pip install --quiet -U git+https://github.com/microsoft/onnxconverter-common\n",
    "!pip install --quiet -U git+https://github.com/onnx/keras-onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "Processing a keras layer - (dense_3: <class 'tensorflow.python.keras.layers.core.Dense'>)\n",
      "\toutput: dense_3/Softmax:0\n",
      "\tinput : dropout_2/cond/Identity:0\n",
      "Processing a keras layer - (dropout_2: <class 'tensorflow.python.keras.layers.core.Dropout'>)\n",
      "\toutput: dropout_2/cond/Identity:0\n",
      "\tinput : dense_2/Relu:0\n",
      "Processing a keras layer - (dense_2: <class 'tensorflow.python.keras.layers.core.Dense'>)\n",
      "\toutput: dense_2/Relu:0\n",
      "\tinput : dropout_1/cond/Identity:0\n",
      "Processing a keras layer - (dropout_1: <class 'tensorflow.python.keras.layers.core.Dropout'>)\n",
      "\toutput: dropout_1/cond/Identity:0\n",
      "\tinput : dense_1/Relu:0\n",
      "Processing a keras layer - (dense_1: <class 'tensorflow.python.keras.layers.core.Dense'>)\n",
      "\toutput: dense_1/Relu:0\n",
      "\tinput : dropout/cond/Identity:0\n",
      "Processing a keras layer - (dropout: <class 'tensorflow.python.keras.layers.core.Dropout'>)\n",
      "\toutput: dropout/cond/Identity:0\n",
      "\tinput : dense/Relu:0\n",
      "Processing a keras layer - (dense: <class 'tensorflow.python.keras.layers.core.Dense'>)\n",
      "\toutput: dense/Relu:0\n",
      "\tinput : dense_input:0\n",
      "var: dense_input\n",
      "var: dense_input:0\n",
      "var: dense_input:01\n",
      "var: dense/Relu:0\n",
      "var: dropout/cond/Identity:0\n",
      "var: dense_1/Relu:0\n",
      "var: dropout_1/cond/Identity:0\n",
      "var: dense_2/Relu:0\n",
      "var: dropout_2/cond/Identity:0\n",
      "var: dense_3/Softmax:01\n",
      "var: dense_3/Softmax:0\n",
      "var: dense_3\n",
      "Converting the operator (Identity): Identity\n",
      "Converting the operator (Identity1): Identity\n",
      "Converting the operator (Identity2): Identity\n",
      "Converting the operator (dense_3): <class 'tensorflow.python.keras.layers.core.Dense'>\n",
      "Converting the operator (dropout_2): <class 'tensorflow.python.keras.layers.core.Dropout'>\n",
      "Converting the operator (keras_learning_phase/input): Const\n",
      "Converting the operator (dense_2): <class 'tensorflow.python.keras.layers.core.Dense'>\n",
      "Converting the operator (dropout_1): <class 'tensorflow.python.keras.layers.core.Dropout'>\n",
      "Converting the operator (dense_1): <class 'tensorflow.python.keras.layers.core.Dense'>\n",
      "Converting the operator (dropout): <class 'tensorflow.python.keras.layers.core.Dropout'>\n",
      "Converting the operator (dense): <class 'tensorflow.python.keras.layers.core.Dense'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras2onnx version is 1.8.0\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 86,610\n",
      "Trainable params: 86,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting the operator (Identity3): Identity\n",
      "The maximum opset needed by this model is only 9.\n"
     ]
    }
   ],
   "source": [
    "import keras2onnx\n",
    "print(\"keras2onnx version is \"+keras2onnx.__version__)\n",
    "# convert to onnx model\n",
    "onnx_model = keras2onnx.convert_keras(model, 'mnist-onnx', debug_mode=1)\n",
    "output_model_path = \"./mnist-model.onnx\"\n",
    "# and save the model in ONNX format\n",
    "keras2onnx.save_model(onnx_model, output_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#ignore warning messages \n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore') \n",
    "\n",
    "# sns.set()\n",
    "\n",
    "###### Voor Tensorflow-GPU ########\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train = pd.read_csv(\"Data/train.csv\")\n",
    "test = pd.read_csv(\"Data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = train[\"label\"]\n",
    "Y_test = test[\"label\"]\n",
    "\n",
    "# Drop 'label' column\n",
    "X_train = train.drop(labels = [\"label\"],axis = 1) \n",
    "X_test = test.drop(labels = [\"label\"],axis = 1) \n",
    "\n",
    "# free some space\n",
    "del train \n",
    "del test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape image in 3 dimensions (height = 28px, width = 28px , channel = 1)\n",
    "X_train = X_train.values.reshape(-1,28,28,1)\n",
    "X_test = X_test.values.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\n",
    "Y_train = to_categorical(Y_train, num_classes = 10)\n",
    "Y_test = to_categorical(Y_test, num_classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the train and the validation set for the fitting\n",
    "# X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = plt.imshow(X_train[2], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the CNN model \n",
    "# my CNN architechture is In -> [[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out\n",
    "\n",
    "model = Sequential(name=\"mnist_model\")\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (28,28,1), name=\"mnist_input\"))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation = \"softmax\", name=\"mnist_output\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer\n",
    "# optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mnist_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mnist_input (Conv2D)         (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 32)        25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "mnist_output (Dense)         (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 887,530\n",
      "Trainable params: 887,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer = \"adam\" , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a learning rate annealer\n",
    "# learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "#                                             patience=3, \n",
    "#                                             verbose=1, \n",
    "#                                             factor=0.5, \n",
    "#                                             min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopper = EarlyStopping(patience=5, verbose=1)\n",
    "epochs = 100 # Turn epochs to 30 to get 0.9967 accuracy\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without data augmentation i obtained an accuracy of 0.98114\n",
    "#history = model.fit(X_train, Y_train, batch_size = batch_size, epochs = epochs, \n",
    "#          validation_data = (X_val, Y_val), verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With data augmentation to prevent overfitting (accuracy 0.99286)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.3861 - accuracy: 0.8761 - val_loss: 0.0835 - val_accuracy: 0.9715\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.1438 - accuracy: 0.9573 - val_loss: 0.0442 - val_accuracy: 0.9857\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.1039 - accuracy: 0.9699 - val_loss: 0.0446 - val_accuracy: 0.9866\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.0935 - accuracy: 0.9714 - val_loss: 0.0301 - val_accuracy: 0.9909\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.0815 - accuracy: 0.9769 - val_loss: 0.0352 - val_accuracy: 0.9901\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.0743 - accuracy: 0.9780 - val_loss: 0.0311 - val_accuracy: 0.9911\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.0667 - accuracy: 0.9793 - val_loss: 0.0313 - val_accuracy: 0.9920\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.0652 - accuracy: 0.9804 - val_loss: 0.0257 - val_accuracy: 0.9936\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0605 - accuracy: 0.9829 - val_loss: 0.0271 - val_accuracy: 0.9928\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.0535 - accuracy: 0.9842 - val_loss: 0.0323 - val_accuracy: 0.9912\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.0558 - accuracy: 0.9835 - val_loss: 0.0244 - val_accuracy: 0.9937\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.0555 - accuracy: 0.9837 - val_loss: 0.0308 - val_accuracy: 0.9904\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0516 - accuracy: 0.9841 - val_loss: 0.0243 - val_accuracy: 0.9934\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.0480 - accuracy: 0.9856 - val_loss: 0.0249 - val_accuracy: 0.9934\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.0490 - accuracy: 0.9853 - val_loss: 0.0278 - val_accuracy: 0.9928\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.0520 - accuracy: 0.9849 - val_loss: 0.0239 - val_accuracy: 0.9934\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.0459 - accuracy: 0.9865 - val_loss: 0.0245 - val_accuracy: 0.9942\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.0473 - accuracy: 0.9857 - val_loss: 0.0228 - val_accuracy: 0.9943\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.0448 - accuracy: 0.9867 - val_loss: 0.0281 - val_accuracy: 0.9931\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.0477 - accuracy: 0.9861 - val_loss: 0.0237 - val_accuracy: 0.9934\n",
      "Epoch 21/100\n",
      "938/938 [==============================] - 12s 12ms/step - loss: 0.0438 - accuracy: 0.9868 - val_loss: 0.0232 - val_accuracy: 0.9939\n",
      "Epoch 22/100\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0403 - accuracy: 0.9873 - val_loss: 0.0304 - val_accuracy: 0.9927\n",
      "Epoch 23/100\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.0445 - accuracy: 0.9869 - val_loss: 0.0235 - val_accuracy: 0.9952\n",
      "Epoch 00023: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n",
    "                              epochs = epochs, validation_data = (X_test,Y_test),\n",
    "                              verbose = 1, callbacks=[earlystopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dink = [0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 4, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 2, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 62, 117, 88, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 143, 255, 161, 254, 197, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 254, 41, 1, 0, 255, 40, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 113, 253, 42, 0, 168, 114, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 96, 255, 49, 167, 110, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 10, 1, 247, 59, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 5, 15, 249, 2, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 1, 0, 173, 153, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 4, 253, 3, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 239, 159, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 1, 0, 2, 0, 2, 0, 2, 124, 232, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 3, 0, 0, 0, 5, 32, 255, 6, 0, 1, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 2, 0, 1, 0, 253, 60, 3, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 3, 0, 197, 148, 6, 0, 3, 123, 9, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 1, 6, 30, 255, 252, 255, 178, 171, 247, 255, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 5, 0, 176, 247, 0, 16, 114, 113, 72, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 3, 1, 0, 0, 2, 0, 0, 6, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "dink = np.array(dink)\n",
    "dink = dink / 255.0\n",
    "g = plt.imshow(dink.reshape(28,28,1), cmap=\"gray\")\n",
    "dink = dink.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(dink.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.8796598e-04 1.7302608e-01 7.6626807e-01 3.3009953e-03 2.7456491e-03\n",
      " 1.3313476e-04 6.5609420e-05 1.6499784e-02 1.7842520e-02 1.9930212e-02]\n",
      "0 has prob of 0.0\n",
      "1 has prob of 0.17000000178813934\n",
      "2 has prob of 0.7699999809265137\n",
      "3 has prob of 0.0\n",
      "4 has prob of 0.0\n",
      "5 has prob of 0.0\n",
      "6 has prob of 0.0\n",
      "7 has prob of 0.019999999552965164\n",
      "8 has prob of 0.019999999552965164\n",
      "9 has prob of 0.019999999552965164\n",
      "Closest number is 2\n"
     ]
    }
   ],
   "source": [
    "# predict results\n",
    "results = model.predict(dink)\n",
    "print(results[0])\n",
    "for i in results[0]:\n",
    "    print(f\"{np.where(results[0] == i)[0][0]} has prob of {round(i,2)}\")\n",
    "\n",
    "# select the indix with the maximum probability\n",
    "results = np.argmax(results,axis = 1)\n",
    "print(f\"Closest number is {results[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras2onnx version is 1.8.0\n"
     ]
    }
   ],
   "source": [
    "# KERAS MODEL OPSLAAN\n",
    "\n",
    "import keras2onnx\n",
    "print(\"keras2onnx version is \"+keras2onnx.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "Processing a keras layer - (mnist_output: <class 'tensorflow.python.keras.layers.core.Dense'>)\n",
      "\toutput: mnist_output/Softmax:0\n",
      "\tinput : dropout_5/cond/Identity:0\n",
      "Processing a keras layer - (dropout_5: <class 'tensorflow.python.keras.layers.core.Dropout'>)\n",
      "\toutput: dropout_5/cond/Identity:0\n",
      "\tinput : dense_2/Relu:0\n",
      "Processing a keras layer - (dense_2: <class 'tensorflow.python.keras.layers.core.Dense'>)\n",
      "\toutput: dense_2/Relu:0\n",
      "\tinput : flatten_1/Reshape:0\n",
      "Processing a keras layer - (flatten_1: <class 'tensorflow.python.keras.layers.core.Flatten'>)\n",
      "\toutput: flatten_1/Reshape:0\n",
      "\tinput : dropout_4/cond/Identity:0\n",
      "Processing a keras layer - (dropout_4: <class 'tensorflow.python.keras.layers.core.Dropout'>)\n",
      "\toutput: dropout_4/cond/Identity:0\n",
      "\tinput : max_pooling2d_3/MaxPool:0\n",
      "Processing a keras layer - (max_pooling2d_3: <class 'tensorflow.python.keras.layers.pooling.MaxPooling2D'>)\n",
      "\toutput: max_pooling2d_3/MaxPool:0\n",
      "\tinput : conv2d_8/Relu:0\n",
      "Processing a keras layer - (conv2d_8: <class 'tensorflow.python.keras.layers.convolutional.Conv2D'>)\n",
      "\toutput: conv2d_8/Relu:0\n",
      "\tinput : conv2d_7/Relu:0\n",
      "Processing a keras layer - (conv2d_7: <class 'tensorflow.python.keras.layers.convolutional.Conv2D'>)\n",
      "\toutput: conv2d_7/Relu:0\n",
      "\tinput : dropout_3/cond/Identity:0\n",
      "Processing a keras layer - (dropout_3: <class 'tensorflow.python.keras.layers.core.Dropout'>)\n",
      "\toutput: dropout_3/cond/Identity:0\n",
      "\tinput : max_pooling2d_2/MaxPool:0\n",
      "Processing a keras layer - (max_pooling2d_2: <class 'tensorflow.python.keras.layers.pooling.MaxPooling2D'>)\n",
      "\toutput: max_pooling2d_2/MaxPool:0\n",
      "\tinput : conv2d_6/Relu:0\n",
      "Processing a keras layer - (conv2d_6: <class 'tensorflow.python.keras.layers.convolutional.Conv2D'>)\n",
      "\toutput: conv2d_6/Relu:0\n",
      "\tinput : mnist_input/Relu:0\n",
      "Processing a keras layer - (mnist_input: <class 'tensorflow.python.keras.layers.convolutional.Conv2D'>)\n",
      "\toutput: mnist_input/Relu:0\n",
      "\tinput : mnist_input_input:0\n",
      "var: mnist_input_input\n",
      "var: mnist_input_input:0\n",
      "var: mnist_input_input:01\n",
      "var: mnist_input/Relu:0\n",
      "var: conv2d_6/Relu:0\n",
      "var: max_pooling2d_2/MaxPool:0\n",
      "var: dropout_3/cond/Identity:0\n",
      "var: conv2d_7/Relu:0\n",
      "var: conv2d_8/Relu:0\n",
      "var: max_pooling2d_3/MaxPool:0\n",
      "var: dropout_4/cond/Identity:0\n",
      "var: flatten_1/Reshape:0\n",
      "var: dense_2/Relu:0\n",
      "var: dropout_5/cond/Identity:0\n",
      "var: mnist_output/Softmax:01\n",
      "var: mnist_output/Softmax:0\n",
      "var: mnist_output\n",
      "Converting the operator (Identity): Identity\n",
      "Converting the operator (Identity1): Identity\n",
      "Converting the operator (Identity2): Identity\n",
      "Converting the operator (mnist_output): <class 'tensorflow.python.keras.layers.core.Dense'>\n",
      "Converting the operator (dropout_5): <class 'tensorflow.python.keras.layers.core.Dropout'>\n",
      "Converting the operator (keras_learning_phase/input): Const\n",
      "Converting the operator (dense_2): <class 'tensorflow.python.keras.layers.core.Dense'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mnist_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mnist_input (Conv2D)         (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 32)        25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "mnist_output (Dense)         (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 887,530\n",
      "Trainable params: 887,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting the operator (flatten_1): <class 'tensorflow.python.keras.layers.core.Flatten'>\n",
      "Converting the operator (flatten_1/Const): Const\n",
      "Converting the operator (dropout_4): <class 'tensorflow.python.keras.layers.core.Dropout'>\n",
      "Converting the operator (max_pooling2d_3): <class 'tensorflow.python.keras.layers.pooling.MaxPooling2D'>\n",
      "Converting the operator (conv2d_8): <class 'tensorflow.python.keras.layers.convolutional.Conv2D'>\n",
      "Converting the operator (conv2d_7): <class 'tensorflow.python.keras.layers.convolutional.Conv2D'>\n",
      "Converting the operator (dropout_3): <class 'tensorflow.python.keras.layers.core.Dropout'>\n",
      "Converting the operator (max_pooling2d_2): <class 'tensorflow.python.keras.layers.pooling.MaxPooling2D'>\n",
      "Converting the operator (conv2d_6): <class 'tensorflow.python.keras.layers.convolutional.Conv2D'>\n",
      "Converting the operator (mnist_input): <class 'tensorflow.python.keras.layers.convolutional.Conv2D'>\n",
      "Converting the operator (Identity3): Identity\n"
     ]
    }
   ],
   "source": [
    "# convert to onnx model\n",
    "onnx_model = keras2onnx.convert_keras(model, 'mnist-onnx-v2', debug_mode=1)\n",
    "output_model_path = \"./mnist-onnx-v2.onnx\"\n",
    "# and save the model in ONNX format\n",
    "keras2onnx.save_model(onnx_model, output_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"mnist_input_input:0\", shape=(None, 28, 28, 1), dtype=float32)\n",
      "mnist_output/Softmax:0\n"
     ]
    }
   ],
   "source": [
    "print(model.inputs[0])\n",
    "print(model.output.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict the test set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00      1195\n",
      "           1       1.00      1.00      1.00      1352\n",
      "           2       1.00      1.00      1.00      1157\n",
      "           3       1.00      1.00      1.00      1258\n",
      "           4       0.99      0.99      0.99      1140\n",
      "           5       0.99      1.00      0.99      1076\n",
      "           6       0.99      1.00      0.99      1167\n",
      "           7       1.00      1.00      1.00      1268\n",
      "           8       0.99      1.00      0.99      1174\n",
      "           9       0.99      0.99      0.99      1213\n",
      "\n",
      "    accuracy                           1.00     12000\n",
      "   macro avg       1.00      1.00      1.00     12000\n",
      "weighted avg       1.00      1.00      1.00     12000\n",
      "\n",
      "[[1187    0    0    1    1    0    6    0    0    0]\n",
      " [   0 1349    0    0    0    0    1    2    0    0]\n",
      " [   1    0 1152    2    0    0    0    1    1    0]\n",
      " [   0    0    0 1254    0    3    0    0    0    1]\n",
      " [   0    1    0    0 1133    0    1    0    1    4]\n",
      " [   0    0    0    1    0 1073    1    0    1    0]\n",
      " [   1    0    0    0    0    3 1162    0    1    0]\n",
      " [   0    0    2    0    1    0    0 1263    1    1]\n",
      " [   0    0    1    0    0    0    1    0 1169    3]\n",
      " [   0    0    0    2    4    3    0    2    2 1200]]\n",
      "99.51666666666667\n"
     ]
    }
   ],
   "source": [
    "print('Predict the test set')\n",
    "predict = model.predict(X_test, batch_size=batch_size)\n",
    "predict = np.argmax(predict,axis=1)\n",
    "class_report = classification_report(Y_test.argmax(axis=1),predict,target_names=[str(i) for i in range(10)])\n",
    "print(class_report)\n",
    "#run.log(\"Classification report\", class_report)\n",
    "\n",
    "cf = confusion_matrix(Y_test.argmax(axis=1), predict)\n",
    "#run.log(\"Confusion Matrix\", cf)\n",
    "\n",
    "print(cf)\n",
    "acc = accuracy_score(Y_test.argmax(axis=1), predict) * 100\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
